{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9c7ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "print(os.listdir(\"Desktop/Projet_Harispe/ChestXRay2017/chest_xray/\")) # lien à remplacer si jamais ça marche pas \n",
    "# On voudrait s'assurer que toutes les images manipulées soient de même dimension si jamais ce n'est pas initialement le cas.\n",
    "taille_img = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e094a501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On va stocker les images et les labels récupérés dans des arrays\n",
    "# Déclaration de listes vides\n",
    "train_images = []\n",
    "train_labels = [] \n",
    "# On déclare le lien vers les images d'entrainement\n",
    "for directory_path in glob.glob(\"Desktop/Projet_Harispe/ChestXRay2017/chest_xray/train/*\"): #changer le lien ici pour que le code puisse fonctionner sur votre ordi\n",
    "    # On récupère les noms des labels\n",
    "    label = directory_path.split(\"\\\\\")[-1]\n",
    "    # Et on les visualise pour s'assurer que tout marche bien pour l'instant.\n",
    "    print(label)\n",
    "    \n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpeg\")):\n",
    "            print(img_path)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_COLOR) #Reading color images\n",
    "            img = cv2.resize(img, (taille_img, taille_img)) #Resize images\n",
    "            \n",
    "            train_images.append(img)\n",
    "            train_labels.append(label)\n",
    "        \n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "print(train_images)\n",
    "print(train_labels) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7216aea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On va stocker les images et les labels récupérés dans des arrays (on fait comme pour les images d'entraînement)\n",
    "# Déclaration de listes vides\n",
    "test_images = []\n",
    "test_labels = [] \n",
    "# On déclare le lien vers les images de test\n",
    "for directory_path in glob.glob(\"Desktop/Projet_Harispe/ChestXRay2017/chest_xray/test/*\"):\n",
    "    # On récupère les noms des labels\n",
    "    label = directory_path.split(\"\\\\\")[-1]\n",
    "    # Et on les visualise pour s'assurer que tout marche bien pour l'instant.\n",
    "    print(label)\n",
    "\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpeg\")):\n",
    "            print(img_path)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_COLOR) #Reading color images\n",
    "            img = cv2.resize(img, (taille_img, taille_img)) #Resize images\n",
    "    \n",
    "            test_images.append(img)\n",
    "            test_labels.append(label)\n",
    "# On stocke les liens des images et les labels dans des array\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "# On print pour vérifier que tout est ok\n",
    "print(test_images)\n",
    "print(test_labels) \n",
    "\n",
    "# On encode les labels sous forme d'entier (facilite l'interprétation par la machine)\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(test_labels)\n",
    "test_labels_encoded = le.transform(test_labels)\n",
    "le.fit(train_labels)\n",
    "train_labels_encoded = le.transform(train_labels)\n",
    "\n",
    "# On sépare les données et labels en données d'entrainement et de test\n",
    "x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded\n",
    "\n",
    "# On normalise les valeurs de pixels entre 0 et 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "\n",
    "\n",
    "# Fonction qui applatit les images en vecteurs unidimensionnels pour en extraire les caractéristiques\n",
    "def feature_extractor(dataset):\n",
    "    #extraction du nombre d'images \n",
    "    num_images = dataset.shape[0]\n",
    "    #calcul de la dimension d'une image : ici hauteur*largeur*canal de couleur\n",
    "    image_size = dataset.shape[1] * dataset.shape[2] * dataset.shape[3]\n",
    "    #Stockage des images applaties dans un array initialisé avec des zéros\n",
    "    image_dataset = np.zeros((num_images, image_size))\n",
    "\n",
    "    for image in range(num_images):\n",
    "        #extraction de l'image courante en extrayant ses dimensions (longueur, largeur, canaux de couleur) pour un indice d'image donné\n",
    "        input_img = dataset[image, :, :, :]\n",
    "        # Applatissement de l'image en un vecteur unidimensionnel (la valeur \"-1\" indique que la nouvelle forme doit être\n",
    "        #compatible avec la taille de l'ancienne forme)\n",
    "        pixel_values = input_img.reshape(-1)\n",
    "        # les valeurs de pixels applaties sont stockés dans la ligne correspondante du tableau \"image_dataset\" contenant les images applaties\n",
    "        image_dataset[image, :] = pixel_values\n",
    "    # retour du tableau contenant les images applaties\n",
    "    return image_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e4758",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Extrait les valeurs de caractéristiques des images d'entraînement\n",
    "image_features = feature_extractor(x_train)\n",
    "\n",
    "# Met les caractéristiques sous forme de vecteur pour les modèles RandomForest et arbre de décision\n",
    "n_features = image_features.shape[1]\n",
    "image_features = np.expand_dims(image_features, axis=0)\n",
    "X_for_RF = np.reshape(image_features, (x_train.shape[0], -1))\n",
    "\n",
    "# On importe les classificateurs RandomForest et DecisionTree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_model = RandomForestClassifier(n_estimators=200, criterion='gini', max_depth=1000, min_samples_split=2, min_samples_leaf=2,\n",
    "                                  max_features='auto',\n",
    "                                  bootstrap=True,\n",
    "                                  n_jobs=-1,\n",
    "                                  random_state=42,\n",
    "                                  verbose=0,\n",
    "                                  warm_start=False,\n",
    "                                  class_weight=None)\n",
    "\n",
    "estimator = DecisionTreeClassifier(criterion='gini',splitter='best', max_depth=100, min_samples_split=2, min_samples_leaf=3,\n",
    "                                   random_state=0,\n",
    "                                   max_leaf_nodes=10,\n",
    "                                   class_weight=None)\n",
    "\n",
    "\n",
    "# On fit chaque modèle sur les données d'entraînement\n",
    "RF_model.fit(X_for_RF, y_train.ravel()) \n",
    "estimator.fit(X_for_RF, y_train.ravel())\n",
    "\n",
    "# Prédictions sur les données test\n",
    "# On extrait les features des données test, comme pour les données d'entraînement, et on les reshape en vecteur\n",
    "test_features = feature_extractor(x_test)\n",
    "test_features = np.expand_dims(test_features, axis=0)\n",
    "test_for_RF = np.reshape(test_features, (x_test.shape[0], -1))\n",
    "\n",
    "# Prédiction des probabilités de classe pour chaque instance de chaque modèle\n",
    "rf_probs = RF_model.predict_proba(test_for_RF)\n",
    "dt_probs = estimator.predict_proba(test_for_RF)\n",
    "\n",
    "# Affichage des probabilités de classe pour les 10 premières instances de test\n",
    "#Ici, les probabilités de classe font référence, pour chaque instance, à la probabilité qu'elle soit classée comme 'NORMAL' ou 'PNEUMONIA'\n",
    "print(\"Probabilités de classes pour RandomForest (10 premieres instances):\")\n",
    "print(rf_probs[:10])\n",
    "\n",
    "print(\"Probabilités de classes pour DecisionTree (10 premières instances):\")\n",
    "print(dt_probs[:10])\n",
    "\n",
    "# Prédictions sur les données tests avec les deux modèles\n",
    "test_prediction = RF_model.predict(test_for_RF)\n",
    "test_prediction1 = estimator.predict(test_for_RF)\n",
    "# On décode les valeurs numériques de label en valeur catégorielle \n",
    "test_prediction = le.inverse_transform(test_prediction)\n",
    "test_prediction1 = le.inverse_transform(test_prediction1)\n",
    "\n",
    "def gini_index(probs):\n",
    "    return 1 - np.sum(np.square(probs), axis=1).mean()\n",
    "rf_gini_index = gini_index(rf_probs)\n",
    "dt_gini_index = gini_index(dt_probs)\n",
    "\n",
    "# Impression des métriques d'exactitude, de précision, de recall, de log-loss et de pureté de Gini pour chaque modèle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, log_loss, f1_score\n",
    "print(\"Random Forest Accuracy = \", metrics.accuracy_score(test_labels.ravel(), test_prediction))\n",
    "print(\"Random Forest Gini Index =\", rf_gini_index)\n",
    "\n",
    "print(\"Decision Tree Accuracy = \", metrics.accuracy_score(test_labels.ravel(), test_prediction1))\n",
    "print(\"Decision Tree Gini Index =\", dt_gini_index)\n",
    "\n",
    "# On imprime deux matrices de confusion (une par modèle) \n",
    "#afin d'évaluer la précision et le rappel du modèle (faux positifs et faux négatifs)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_labels.ravel(), test_prediction)\n",
    "fig, ax = plt.subplots(figsize=(6,6))         # Sample figsize in inches\n",
    "sns.set(font_scale=1.6)\n",
    "sns.heatmap(cm, annot=True, ax=ax)\n",
    "\n",
    "\n",
    "cm1 = confusion_matrix(test_labels.ravel(), test_prediction1)\n",
    "fig, ax = plt.subplots(figsize=(6,6))         # Sample figsize in inches\n",
    "sns.set(font_scale=1.6)\n",
    "sns.heatmap(cm1, annot=True, ax=ax)\n",
    "\n",
    "# On effectue les prédictions sur chaque image de l'ensemble test\n",
    "for i in range(x_test.shape[0]):\n",
    "    img = x_test[i]\n",
    "    # Extraction des features et reshaping dans les bonnes dimensions\n",
    "    input_img = np.expand_dims(img, axis=0) # On rajoute une dimension pour que l'input soit de la forme(num images, x, y, c)\n",
    "    input_img_features=feature_extractor(input_img)\n",
    "    input_img_features = np.expand_dims(input_img_features, axis=0)\n",
    "    input_img_for_RF = np.reshape(input_img_features, (input_img.shape[0], -1))\n",
    "\n",
    "    # Predictions pour chaque modèle\n",
    "    img_prediction = RF_model.predict(input_img_for_RF)\n",
    "    img_prediction = le.inverse_transform([img_prediction])  #Reverse the label encoder to original name\n",
    "    print(\"La prédiction pour l'image \", i, \" est: \", img_prediction)\n",
    "    print(\"Le véritable label pour l'image \", i, \" est: \", test_labels[i])\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    img_prediction1 = estimator.predict(input_img_for_RF)\n",
    "    img_prediction1 = le.inverse_transform([img_prediction1])  #Reverse the label encoder to original name\n",
    "    print(\"La prédiction pour l'image \", i, \" est: \", img_prediction1)\n",
    "    print(\"Le véritable label pour l'image \", i, \" est: \", test_labels[i])\n",
    "    plt.imshow(img) #pour voir l'image associée à la prédiction\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc07149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4765eace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2824183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels.ravel(), test_prediction, target_names =['Normal (Class 0)' , 'Pneumonia (Class 1)']))\n",
    "print(classification_report(test_labels.ravel(), test_prediction1, target_names =['Normal (Class 0)' , 'Pneumonia (Class 1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136ad5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Voici les métriques pour la foret aléatoire\n",
    "metrics_model1 = {'accuracy': 0.764, 'precis': 0.818, 'recall': 0.764, 'f1': 1 - 0.268, 'gini_index': 0.213}\n",
    "\n",
    "# Voici les métriques pour l'arbre de décision\n",
    "metrics_model2 = {'accuracy': 0.700, 'precis': 0.718, 'recall': 0.700, 'f1': 1 - 0.343, 'gini_index': 0.175}\n",
    "\n",
    "bar_width = 0.35\n",
    "positions_model1 = np.arange(len(metrics_model1))\n",
    "positions_model2 = [x + bar_width for x in positions_model1]\n",
    "\n",
    "# On crée le graphe en bâtons\n",
    "fig, ax = plt.subplots()\n",
    "bars_model1 = ax.bar(positions_model1, metrics_model1.values(), width=bar_width, label=\"Random Forest\", color='b')\n",
    "bars_model2 = ax.bar(positions_model2, metrics_model2.values(), width=bar_width, label=\"Decision Tree\", color='g')\n",
    "\n",
    "# On ajoute les étiquettes et les titres, et la légende\n",
    "ax.set_xticks([r + bar_width / 2 for r in range(len(metrics_model1))])\n",
    "ax.set_xticklabels(metrics_model1.keys())\n",
    "ax.set_ylabel('Valeur')\n",
    "ax.set_title('Comparaison des métriques entre les deux modèles')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba30b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
